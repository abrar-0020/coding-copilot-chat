import streamlit as st
import google.generativeai as genai
import pdfplumber
import mimetypes
from PIL import Image
import io

# ğŸ”¹ Configure Gemini API
API_KEY = "your_gemini_api_key_here"
genai.configure(api_key=API_KEY)
MODEL_NAME = "gemini-1.5-flash"

# â”€â”€ Query Gemini â”€â”€
def query_gemini_text(prompt: str) -> str:
    """Send text prompt to Gemini."""
    try:
        model = genai.GenerativeModel(MODEL_NAME)
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"âŒ Gemini API Error: {e}"

def query_gemini_image(image_bytes, prompt="Describe this image.") -> str:
    """Send an image with an optional prompt to Gemini."""
    try:
        model = genai.GenerativeModel(MODEL_NAME)
        image = Image.open(io.BytesIO(image_bytes))
        response = model.generate_content([prompt, image])
        return response.text
    except Exception as e:
        return f"âŒ Gemini Image Analysis Error: {e}"

# â”€â”€ Extract Text from PDF â”€â”€
def extract_text_from_pdf(file_bytes):
    text = ""
    with pdfplumber.open(io.BytesIO(file_bytes)) as pdf:
        for page in pdf.pages:
            text += page.extract_text() or ""
    return text

# â”€â”€ Streamlit UI â”€â”€
st.set_page_config(page_title="AI File Analyzer (Gemini)", page_icon="ğŸ¤–")

# â”€â”€ Sidebar â”€â”€
st.sidebar.title("âš™ï¸ Options")
if st.sidebar.button("ğŸ†• New Chat"):
    st.session_state.clear()

# â”€â”€ Session State â”€â”€
if "messages" not in st.session_state:
    st.session_state.messages = []
if "file_processed" not in st.session_state:
    st.session_state.file_processed = False

# Display chat history
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# â”€â”€ File Upload â”€â”€
uploaded_file = st.file_uploader("Upload any file (image, PDF, text, etc.)", type=None)

if uploaded_file and not st.session_state.file_processed:
    file_type, _ = mimetypes.guess_type(uploaded_file.name)
    file_bytes = uploaded_file.read()

    # âœ… Handle Images
    if file_type and file_type.startswith("image"):
        with st.chat_message("user"):
            st.markdown(f"ğŸ“· **Uploaded Image:** {uploaded_file.name}")
            st.image(file_bytes)

        st.session_state.messages.append({"role": "user", "content": f"ğŸ“· Uploaded Image: {uploaded_file.name}"})

        with st.spinner("ğŸ’­ Analyzing image with Gemini..."):
            reply = query_gemini_image(file_bytes, "Explain this image in detail.")
        st.session_state.messages.append({"role": "assistant", "content": reply})
        with st.chat_message("assistant"):
            st.markdown(reply)

    # âœ… Handle PDFs
    elif file_type == "application/pdf":
        text = extract_text_from_pdf(file_bytes)
        with st.chat_message("user"):
            st.markdown(f"ğŸ“„ **Uploaded PDF:** {uploaded_file.name}")
            st.code(text[:1000] + "..." if len(text) > 1000 else text)
        st.session_state.messages.append({"role": "user", "content": f"ğŸ“„ Uploaded PDF: {uploaded_file.name}"})

        with st.spinner("ğŸ’­ Analyzing PDF with Gemini..."):
            reply = query_gemini_text(f"Explain this PDF content:\n{text[:4000]}")
        st.session_state.messages.append({"role": "assistant", "content": reply})
        with st.chat_message("assistant"):
            st.markdown(reply)

    # âœ… Handle Text Files
    elif file_type and ("text" in file_type or file_type.endswith("json")):
        text = file_bytes.decode("utf-8", errors="ignore")
        with st.chat_message("user"):
            st.markdown(f"ğŸ“„ **Uploaded File:** {uploaded_file.name}")
            st.code(text[:1000] + "..." if len(text) > 1000 else text)
        st.session_state.messages.append({"role": "user", "content": f"ğŸ“„ Uploaded File: {uploaded_file.name}"})

        with st.spinner("ğŸ’­ Analyzing file content with Gemini..."):
            reply = query_gemini_text(f"Explain this file content:\n{text[:4000]}")
        st.session_state.messages.append({"role": "assistant", "content": reply})
        with st.chat_message("assistant"):
            st.markdown(reply)

    # âŒ Unsupported Files (video, audio, etc.)
    else:
        with st.chat_message("assistant"):
            st.warning("âŒ This file type is not fully supported yet. Try uploading text, PDF, or images.")
        st.session_state.messages.append({"role": "assistant", "content": "âŒ Unsupported file type."})

    st.session_state.file_processed = True

# â”€â”€ Chat Input (Only Current Prompt â†’ Response) â”€â”€
user_input = st.chat_input("Ask a question about your uploaded file or anything else...")

if user_input:
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    with st.spinner("ğŸ’­ Thinking..."):
        reply = query_gemini_text(user_input)

    st.session_state.messages.append({"role": "assistant", "content": reply})
    with st.chat_message("assistant"):
        st.markdown(reply)
